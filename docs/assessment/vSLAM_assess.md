# 視覺建圖 (vSLAM) 可行性與運算能力評估

這份文件評估了使用視覺辨識來建構地圖 (vSLAM) 的可行性，以及在一台 i7 筆記型電腦上運行的效能需求。

---

### 1. 視覺建圖的可行性 (演算法層面)

透過視覺辨識來定義地圖是完全可行的，此技術稱為 **vSLAM (Visual Simultaneous Localization and Mapping)**。

**基本原理：**

1.  **特徵提取 (Feature Extraction):** 從攝影機影像中尋找穩定的特徵點 (如角落、邊緣)。
2.  **運動估計 (Motion Estimation / Visual Odometry):** 比較連續影像中特徵點的移動，估算攝影機 (車輛) 的運動軌跡。
3.  **地圖建構 (Mapping):** 利用三角測量，將 2D 影像的特徵點轉換為 3D 空間中的點，逐步建立三維點雲地圖。
4.  **迴圈閉合 (Loop Closure):** 當車輛回到先前經過的位置時，演算法能識別出場景，並修正累積的路徑和地圖誤差。這是 SLAM 的關鍵步驟。

**可產生的地圖類型：**

*   **稀疏點雲地圖 (Sparse Map):** 由關鍵特徵點組成，適用於定位，但難以直接用於導航。
*   **稠密地圖 (Dense Map):** 為影像中幾乎所有像素估算深度，形成完整的 3D 模型，適合導航，但運算量極大。

**主要挑戰：**

*   **計算量大：** vSLAM 的核心瓶頸。
*   **環境依賴性：** 在特徵稀少 (如白牆)、光線變化劇烈或多動態物體的環境中容易失敗。
*   **運動模糊：** 車輛移動過快會影響特徵追蹤的穩定性。

---

### 2. i7 筆電的運算能力支撐

一台**中高階的 i7 筆電**足以運行經典的 vSLAM 演算法 (如 ORB-SLAM2/3)，但會非常吃力。

**評估指標：**

*   **CPU:** vSLAM 是 CPU 密集型任務。建議使用擁有 6-8 核心及高時脈的現代 i7 CPU。預期 CPU 會處於高負載狀態。
*   **RAM:** 地圖建構會消耗大量記憶體。建議至少 **16GB RAM**，32GB 更佳。
*   **GPU:** 雖然非必要，但部分現代 vSLAM 演算法可利用 GPU 加速特徵提取等環節。若使用基於深度學習的方法，NVIDIA GPU 將是必要的。
*   **影像規格:** 建議從 640x480 @ 30fps 的影像流開始測試，以平衡細節和運算負擔。

**結論：**

i7 筆電**有能力**運行一個開源的 vSLAM 專案，並在理想環境下建構一個稀疏點雲地圖。

**預期情況：**

1.  **高 CPU 使用率：** 可能超過 80%，可能影響後端服務的回應速度。
2.  **開發複雜度高：** 任務龐大，建議將 vSLAM 作為獨立行程運行，並透過行程間通訊 (IPC) 與主控制程式整合。
3.  **後續處理：** 從稀疏地圖到可用的導航地圖，需要額外的處理步驟 (如地面投影、障礙物膨脹等)。

---

### 建議路徑

*   **短期目標:** 專注於完善現有的**反應式避障 (Reactive Navigation)** 邏輯，此方法不建立地圖，僅根據即時感測器數據反應，穩定且計算成本低。
*   **中期目標:** 嘗試**視覺里程計 (Visual Odometry)**，僅估算運動軌跡，不建構地圖。可了解相對運動，但誤差會隨時間累積。
*   **長期目標:** 若決定挑戰 vSLAM，建議使用成熟的開源庫 (如 **ORB-SLAM3**)，並將其作為獨立模組開發，再與現有系統整合。


---
---

# 簡易視覺避障可行性與 i5 筆電運算能力評估

這份評估分析了在 i5 筆電上，透過視覺辨識完成簡易避障任務的可行性。

**總結：可行。一台 i5 筆電絕對有能力完成此任務。**

---

### 1. 可行性與常用方法

簡易視覺避障是一種**反應式 (Reactive)** 策略，不建立地圖，僅根據當前畫面做立即決策。最常見且計算成本低的方法是**基於輪廓 (Contour-based) 的障礙物偵測**。

**處理流程：**

1.  **獲取影像幀 (Frame):** 從攝影機串流讀取畫面。
2.  **預處理 (Preprocessing):m**
    *   **灰階轉換 (Grayscale):** 將 RGB 影像轉為單色版，減少計算量。
    *   **高斯模糊 (Gaussian Blur):** 去除雜訊，平滑邊緣。
3.  **二值化 (Thresholding):** 將影像轉為純黑白，將障礙物與背景分離。
4.  **輪廓偵測 (Find Contours):** 找出黑白影像中所有連續封閉區域的邊界。
5.  **分析與過濾 (Analysis & Filtering):**
    *   過濾掉細小的雜訊輪廓。
    *   專注於面積最大的輪廓 (假設為障礙物)。
    *   計算其**面積 (Area)** 和**中心點 (Centroid)**。
6.  **決策 (Decision Making):**
    *   根據障礙物的面積和位置，執行閃避邏輯 (例如：前方有障礙物則轉彎，面積過大則後退)。

---

### 2. i5 筆電的運算能力

對於上述流程，一台**任何世代的 i5 筆電**都**綽綽有餘**。

*   **CPU 負載:** 使用 OpenCV 優化過的函式，處理中低解析度 (如 640x480) 影像串流時，CPU 負載預期僅會增加 10-40%，完全在可接受範圍內。
*   **RAM 消耗:** 記憶體消耗極小，可以忽略不計。
*   **影像規格:** 可輕鬆處理 640x480 @ 30fps 的影像。若 CPU 負載較高，可降低解析度或處理幀率 (15-20fps) 仍能獲得良好效果。

---

### 3. 挑戰與限制

此簡易方法本身存在固有局限性：

*   **對光線敏感:** 陰影和反光可能被誤判為障礙物。
*   **對背景要求高:** 複雜的地板圖案會產生干擾，單純顏色的背景效果最好。
*   **無法應對複雜場景:** 無法理解「U」字形陷阱，可能導致車輛卡在角落。
*   **無法識別低矮或顏色相近的物體:** 如地面上的電線。

### 結論

**絕對可行。** i5 筆電完全有能力執行基於輪廓偵測的簡易視覺避障。目前的軟體架構是正確的，只需在 `CameraStreamProcessor` 中完整實現 OpenCV 處理流程，並將分析結果回傳給決策邏輯即可。

---
---

# 避障方案評估：超音波 vs. 視覺 vs. 感測器融合

這份評估比較了單獨使用超音波、單獨使用視覺以及兩者併用的避障方案。

**結論：強烈建議併用方案 (感測器融合)，此方案遠優於任何單一方案。**

---

### 感測器特性比較

| 特性 | 超音波感測器 (如 HC-SR04) | 視覺辨識 (攝影機) |
| :--- | :--- | :--- |
| **工作原理** | 主動式：發射聲波，測量回波時間 (ToF) | 被動式：接收環境光，進行影像處理 |
| **輸出數據** | **直接、精確的距離值 (公分/英吋)** | **間接的 2D 影像資訊** (輪廓、顏色、紋理) |
| **計算成本** | **極低** (由 Arduino 直接處理) | **高** (需要在 i5/i7 筆電上進行密集運算) |
| **優點** | - 不受光線、陰影、顏色影響<br>- 在黑暗中完美運作<br>- 直接提供距離，無需推斷<br>- 對於偵測大面積、平坦的障礙物非常可靠 | - 提供豐富的資訊 (形狀、顏色、紋理)<br>- 視野 (Field of View) 寬廣<br>- 能偵測到超音波會忽略的物體 (如細長的桌腳)<br>- 能識別地面上的標記 (如線條) |
| **弱點** | - **偵測範圍是狹窄的圓錐體**，像「隧道視野」<br>- 可能無法偵測到吸音材質 (如布料)<br>- 可能無法偵測到極小或不平整的物體<br>- 容易被其他超音波源干擾 | - **極易受光線變化、陰影、反光影響**<br>- 對於透明或無紋理的表面 (如玻璃、白牆) 效果差<br>- 無法直接測量距離，只能透過面積等間接推斷<br>- 計算量大，有延遲 |

---

### 方案評估

*   **方案一：僅使用超音波:** 簡單可靠，但有「隧道視野」盲區。
*   **方案二：僅使用視覺:** 視野寬廣，但極易受環境影響而產生誤判或漏判。
*   **方案三：兩者併用 (感測器融合):** **最佳選擇**。核心思想是用一個感測器的優點彌補另一個的缺點，實現遠高於單一感測器的可靠性。
    *   **範例1 (超音波否決視覺):** 視覺因陰影誤判有障礙，但超音波回報無障礙，則信任超音波，繼續前進。
    *   **範例2 (視覺補充超音波):** 超音波因盲區漏掉桌腳，但視覺偵測到輪廓，則信任視覺，立即避障。

### 實作建議

1.  **硬體:** 將超音波感測器 (HC-SR04) 連接到 Arduino 的數位 I/O 腳位。
2.  **Arduino:** 在韌體中讀取超音波距離，並將其加入到傳送給後端的 JSON 酬載中 (例如，新增 `"u": 55` 欄位)。
3.  **Python 後端:** 修改 Pydantic 模型以接收距離數據，並在決策邏輯中整合此數據，實現融合演算法。

---
---

# 超音波感測器對 I2C 匯流排的影響評估

這份評估分析了啟用超音波感測器是否會對 I2C 匯流排 (已被熱成像儀使用) 造成瓶頸。

**結論：完全不會。**

---

### 1. 硬體介面分析

*   **I2C 匯流排:** 熱成像儀 (AMG8833) 和 ESP32-S3 視覺模組使用此介面。它是一個雙線式串列匯流排 (SDA/SCL)。
*   **超音波感測器 (HC-SR04):** 使用獨立的數位 GPIO 腳位 (Trig/Echo)，與 I2C 腳位完全無關。

因為兩者使用不同的硬體介面，所以在匯流排層面**不存在任何資源競爭或衝突**。

### 2. 真正的瓶頸：阻塞式操作

在 Arduino 這種單執行緒微控制器上，真正的瓶頸來源於**阻塞 (Blocking)** 整個程式執行的操作，而非 I2C 本身。

*   **I2C 讀取時間 (熱成像儀):** 約 **3-5 毫秒**。非常快，幾乎不構成瓶頸。
*   **超音波讀取時間 (`pulseIn()`):** 與距離成正比，通常為 **5-20 毫秒**。這是主要的潛在瓶頸。
*   **`pulseIn()` 超時風險:** 如果未收到回波，預設的 `pulseIn()` 會阻塞程式長達 **1 秒**，這會導致系統嚴重卡頓。

### 最佳實踐與建議

1.  **放心啟用超音波感測器:** 它不會影響 I2C 通訊。
2.  **管理 `pulseIn()` 阻塞:**
    *   **設定合理超時:** 呼叫 `pulseIn()` 時，務必提供第三個參數來限制最大等待時間，例如 `pulseIn(echoPin, HIGH, 30000)` 將超時設為 30 毫秒。
    *   **(進階) 使用非阻塞函式庫:** 考慮使用如 `NewPing` 的函式庫，它利用計時器中斷，完全不會阻塞主迴圈。

**最終結論：** 啟用超音波感測器並採用感測器融合策略，其效益遠大於其微小的時間成本。需要管理的不是 I2C 衝突，而是 `pulseIn()` 函式的阻塞時間，而這個問題有成熟的解決方案。